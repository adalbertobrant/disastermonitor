# src/llm_adapter.py
import logging
import google.generativeai as genai
from src.config import GOOGLE_API_KEY, GEMINI_MODEL_NAME, GEMINI_TEMPERATURE, GEMINI_MAX_OUTPUT_TOKENS

logger = logging.getLogger(__name__)

class GeminiAdapter:
    def __init__(self):
        if not GOOGLE_API_KEY:
            logger.error("GOOGLE_API_KEY not found. Please set it in your .env file.")
            raise ValueError("GOOGLE_API_KEY not configured.")
        
        genai.configure(api_key=GOOGLE_API_KEY)
        self.model = genai.GenerativeModel(GEMINI_MODEL_NAME)
        self.generation_config = genai.types.GenerationConfig(
            temperature=GEMINI_TEMPERATURE,
            max_output_tokens=GEMINI_MAX_OUTPUT_TOKENS
        )
        logger.info(f"Google Generative AI model '{GEMINI_MODEL_NAME}' initialized.")

    def generate_text(self, prompt: str) -> str:
        """Generates text using the configured Gemini model."""
        try:
            response = self.model.generate_content(
                prompt,
                generation_config=self.generation_config
            )
            # Handle cases where response might not have 'text' or is blocked
            if response.parts:
                return response.text
            elif response.prompt_feedback and response.prompt_feedback.block_reason:
                block_reason = response.prompt_feedback.block_reason
                logger.warning(f"Content generation blocked. Reason: {block_reason}")
                return f"Content generation blocked: {block_reason}. Please review prompt or safety settings."
            else:
                logger.warning(f"No content generated. Full response: {response}")
                return "No content generated by the model."

        except Exception as e:
            logger.error(f"Error during Google AI text generation: {e}", exc_info=True)
            return f"Error generating text: {str(e)}"

def generate_agent_prompt(agent_role_description: str, current_context: str, previous_insights: str = "") -> str:
    """
    Generates a structured prompt for an agent.
    """
    prompt = f"""
You are a specialized AI agent: {agent_role_description}.
Your task is to analyze the provided information within a multi-agent system monitoring disaster and economic signals.

**Current Real-Time Data & Context:**
---
{current_context}
---

"""
    if previous_insights:
        prompt += f"""
**Insights from Other Agents (Analyze and build upon these):**
---
{previous_insights}
---
"""

    prompt += """
**Your Analysis (Provide in a structured manner):**

1.  **Key Observations:**
    *   [Identify 2-3 most critical pieces of information from the context relevant to your role.]
    *   [Observation 2]
    *   [Observation 3, if any]

2.  **Probable Scenarios & Likelihood (based on your expertise):**
    *   Scenario 1: [Describe a potential scenario] (Likelihood: [Low/Medium/High])
    *   Impacts: [Specific impacts related to your domain]
    *   Scenario 2 (Optional): [Describe another] (Likelihood: [Low/Medium/High])
    *   Impacts: [Specific impacts related to your domain]

3.  **Economic & Financial Market Implications (from your perspective):**
    *   [How might this affect specific sectors, commodities, currencies, or overall market sentiment?]
    *   [Are there early indicators for financial market shifts?]

4.  **Information Gaps & Next Steps:**
    *   [What additional information would be useful?]
    *   [What should other agents focus on or look for?]

**Output Format:**
Provide your response in clear, concise text. Focus on actionable insights.
Do not repeat the prompt. Start directly with your analysis.
"""
    return prompt
